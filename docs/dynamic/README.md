# Dynamic Scene Reconstruction

## üé¨ Overview

The Dynamic Scene Reconstruction category extends DUSt3R's capabilities from static scenes to the temporal domain, handling motion, deformation, and time-varying geometry. These papers tackle the fundamental challenge of understanding 4D scenes (3D + time) from visual input, enabling applications in video understanding, robotics, and immersive media.

## üéØ Key Challenges

Dynamic scenes introduce complexity beyond static reconstruction:

1. **Temporal Consistency**: Maintaining coherent geometry across frames
2. **Motion Disentanglement**: Separating camera motion from object motion
3. **Scale Consistency**: Preserving metric scale throughout sequences
4. **Memory Efficiency**: Handling long videos without exhausting resources
5. **Real-time Processing**: Achieving online performance for applications

## üìö Paper List (11 papers)

### üèÉ Motion Modeling & Tracking
1. [**POMATO**: Pointmap Matching with Temporal Motion for Dynamic Scene Reconstruction](pomato.md)
   - **Venue**: ICCV 2025
   - **Innovation**: Unified framework for pointmap matching + motion
   - **Key**: Handles complex dynamic scenes

2. [**MonST3R**: Monocular Tracking and Reconstruction](monst3r.md)
   - **Venue**: ICLR 2025
   - **Innovation**: Per-frame pointmaps with temporal links
   - **Key**: Robust monocular video processing

3. [**Easi3R**: Efficient Attention for Single Image-to-3D Reconstruction](easi3r.md)
   - **Venue**: ICCV 2025
   - **Innovation**: Training-free motion from attention patterns
   - **Key**: Zero-shot dynamic understanding

4. [**D¬≤USt3R**: Dense Depth from Uncalibrated Dynamic Stereo Videos](d2ust3r.md)
   - **Venue**: arXiv 2025
   - **Innovation**: 4D pointmap regression
   - **Key**: Direct 4D reconstruction

### ‚è±Ô∏è Temporal Consistency
5. [**CUT3R**: Continuous 3D Perception via Memory](cut3r.md)
   - **Venue**: CVPR 2025
   - **Innovation**: Persistent 3D state across time
   - **Key**: Long-term scene understanding

6. [**Align3R**: Aligned Monocular Depth for Dynamic Videos](align3r.md)
   - **Venue**: CVPR 2025
   - **Innovation**: Scale-consistent depth across frames
   - **Key**: Solves scale drift problem

7. [**Dynamic Point Maps**: Efficient 4D Representation](dynamic-point-maps.md)
   - **Venue**: arXiv 2025
   - **Innovation**: Versatile 4D scene representation
   - **Key**: Memory-efficient design

### üë• Specialized Applications
8. [**ODHSR**: One-shot Deformable Human and Scene Reconstruction](odhsr.md)
   - **Venue**: CVPR 2025
   - **Innovation**: Joint human-scene understanding
   - **Key**: Handles human-object interaction

9. [**Geo4D**: Learning 4D Geometric Representations](geo4d.md)
   - **Venue**: ICCV 2025  
   - **Innovation**: Video generators for 4D
   - **Key**: Generative 4D modeling

10. [**Stereo4D**: Learning How Things Move from Internet Videos](stereo4d.md)
    - **Venue**: CVPR 2025
    - **Innovation**: Self-supervised motion learning
    - **Key**: Learns from wild videos

11. [**Adapt3R**: Adaptive 3D Scene Representation](adapt3r.md)
    - **Venue**: arXiv 2025
    - **Innovation**: Domain adaptation for dynamic scenes
    - **Key**: Generalizes across domains

## üí° Technical Approaches & Innovations

### 1. **Temporal Extension Strategies**

**Architecture Modifications**:
- **Temporal Attention**: Cross-frame feature correlation (MonST3R, CUT3R)
- **Recurrent Processing**: Memory-based architectures (CUT3R)
- **4D Representations**: Joint space-time modeling (D¬≤USt3R, Dynamic Point Maps)

**Key Innovation**: Moving from 3D snapshots to continuous 4D understanding

### 2. **Motion Disentanglement Methods**

**Decomposition Strategies**:
- **Two-stream Networks**: Separate camera and object motion (POMATO)
- **Attention-based**: Motion from self-attention patterns (Easi3R)
- **Scene Flow**: Dense 3D motion fields (Stereo4D)

**Key Innovation**: Understanding "what moves" vs "how we move"

### 3. **Consistency Enforcement Techniques**

**Temporal Coherence**:
- **Cross-frame Constraints**: Enforcing geometric consistency (Align3R)
- **Scale Anchoring**: Preventing drift over time (MonST3R)
- **Memory Networks**: Maintaining persistent state (CUT3R)

**Key Innovation**: Solving the scale drift problem in monocular video

## üîß Performance & Trade-offs

### Speed vs Accuracy
| Method | FPS | Temporal Window | Key Trade-off |
|--------|-----|-----------------|---------------|
| Easi3R | 30+ | Single frame | Fast but limited context |
| MonST3R | 10-15 | 5-10 frames | Balanced performance |
| CUT3R | 5-10 | Unlimited | Full consistency, slower |
| D¬≤USt3R | 1-5 | Full video | Highest quality, offline |

### Memory Requirements
- **Frame-based**: O(1) memory (Easi3R)
- **Window-based**: O(k) memory (MonST3R, POMATO)
- **Full sequence**: O(n) memory (D¬≤USt3R, CUT3R)

## üéØ Applications & Use Cases

### Current Applications
1. **Autonomous Navigation**: Understanding dynamic environments
2. **AR/VR Content**: Creating immersive experiences
3. **Video Editing**: 3D-aware video manipulation
4. **Robotics**: Interacting with moving objects
5. **Medical Imaging**: Tracking organ motion

### Enabled Capabilities
- **Novel View Synthesis**: Of dynamic scenes
- **4D Reconstruction**: Complete spatiotemporal models
- **Motion Prediction**: Anticipating future states
- **Scene Understanding**: Semantic motion analysis

## üìä Benchmarks & Evaluation

### Standard Datasets
| Dataset | Type | Metrics | Focus |
|---------|------|---------|-------|
| **Dynamic Replica** | Synthetic | Accuracy, completeness | Indoor dynamics |
| **TartanAir** | Synthetic | Trajectory error | Outdoor navigation |
| **KITTI** | Real | Depth, flow accuracy | Autonomous driving |
| **Sintel** | Synthetic | Optical flow EPE | Complex motion |
| **DyCheck** | Real | Novel view quality | View synthesis |

### Evaluation Metrics
- **Geometric**: Depth accuracy, trajectory error
- **Motion**: Flow endpoint error, tracking accuracy
- **Temporal**: Consistency scores, drift metrics
- **Perceptual**: Novel view PSNR/SSIM

## üöÄ Future Directions

### Near-term Goals
1. **Real-time 4D**: Achieving 30+ FPS for all methods
2. **Longer Videos**: Handling hour-long sequences
3. **Better Motion**: Non-rigid and articulated objects
4. **Uncertainty**: Quantifying temporal predictions

### Long-term Vision
1. **Unified 4D Foundation Models**: One model for all spatiotemporal tasks
2. **Physics Integration**: Incorporating physical priors and constraints
3. **Language-guided 4D**: "Show me when the person picks up the cup"
4. **Predictive Models**: Forecasting future 3D states
5. **Interactive 4D**: Real-time editing of dynamic scenes

## üîó Relationship to DUSt3R Ecosystem

**Building on Foundation**:
- Extends DUSt3R's feed-forward paradigm to time
- Leverages pretrained spatial understanding
- Maintains uncalibrated, accessible approach

**Synergies with Other Categories**:
- **Gaussian Splatting**: 4D Gaussians for dynamics
- **Understanding**: Semantic motion analysis
- **Robotics**: Perception for manipulation
- **Medical**: Tracking deformable tissues

---

*Dynamic Scene Reconstruction represents the frontier of 4D vision, extending DUSt3R's revolutionary approach from spatial to spatiotemporal understanding. These methods are paving the way for AI systems that truly understand how the world moves and changes.*