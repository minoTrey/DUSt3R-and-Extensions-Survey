# Scene Understanding Papers

This directory contains documentation for papers focused on semantic understanding and perception in 3D reconstruction.

## Papers in this Category

1. [PE3R: Perception-Efficient 3D Reconstruction](pe3r.md) - A feed-forward framework that enables fast and generalizable 3D semantic reconstruction with improved perception accuracy and 9× speedup.

2. [MEt3R: Measuring Multi-View Consistency in Generated Images](met3r.md) - A metric that uses DUSt3R-based reconstructions to evaluate geometric consistency of multi-view generated images.

3. LargeSpatialModel: End-to-end Unposed Images to Semantic 3D - Proposes a transformer-based architecture that jointly reconstructs geometry, appearance, and semantics from unposed RGB images in a single feed-forward pass.

4. MONO3R: Exploiting Monocular Cues for Geometric 3D Reconstruction - Matching 기반 3D 재구성의 한계를 보완하기 위해, 모노큘러 기하 정보로 다시 정제하는 Mono3R을 제안하여, 악조건에서도 강건한 scene reconstruction을 달성.

5. Regist3r: A Unified Model for General-Purpose Pairwise Registration - Proposes a unified transformer-based model that performs general-purpose pairwise registration across diverse data modalities including RGB, depth, point clouds, and neural radiance fields.